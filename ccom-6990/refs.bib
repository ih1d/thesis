@inproceedings{mlpl,
  title={On machine learning and programming languages},
  author={Innes, Mike and Karpinski, Stefan and Shah, Viral and Barber, David and Saito Stenetorp, PLEPS and Besard, Tim and Bradbury, James and Churavy, Valentin and Danisch, Simon and Edelman, Alan and others},
  year={2018},
  organization={Association for Computing Machinery (ACM)},
  annotate={This paper discusses the necessity of a first class language for machine learning (ML) . It explains that Python is the metalanguage used to build expressions in 
TensorFlow's internal language. So, TensorFlow does not provide you with functions and data structures, it provides a graph-based language which you manipulate through it's 
API. The authors turn to answer the question: Why create a new language? Since ML models are becoming more complex there is a necessity to add more language constructs to
TensorFlow's internal language (conditionals, loops, recursions, etc.). Another reason presented is that using a meta-language poses more challenges in order to reason about 
programs since one needs to reason about the meta-language semantics and the internal language's. This is also a burden for the compiler since it is tracing two executions.
One approach presented is "define-by-run" where a program is itself the model, using runtime automatic differentiation (AD). However, ML is computational heavy and this
approach falls short. The authors present the idea of programmable semantics because of the possible flexibility it may allow, providing features similar to macros. For example,
One could specify where the code should have dataflow semantics. Another idea for such a language would be to have first-class derivatives, mixing symbolic with runtime techniques.
}
}

@inproceedings{abadi2017computational,
  title={A computational model for TensorFlow: an introduction},
  author={Abadi, Mart{\'\i}n and Isard, Michael and Murray, Derek G},
  booktitle={Proceedings of the 1st ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
  pages={1--7},
  year={2017},
  annotate={This paper discusses how TensorFlow works under the hood, by explaining a very limited version of TensorFlow's dataflow computational model.
  The limited version contains variables, tensors, and read and write operations on variables. The authors explain the semantics of these operations, and how the dataflow graph behaves.}
}